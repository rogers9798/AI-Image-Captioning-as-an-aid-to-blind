{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import pickle\n",
    "import pyttsx3\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "model = load_model(\"model_weights/model_19.h5\")\n",
    "model_temp = ResNet50(weights=\"imagenet\", input_shape=(224,224,3))\n",
    "model_resnet = Model(model_temp.input, model_temp.layers[-2].output)\n",
    "\n",
    "def preprocess_image(img):\n",
    "    img = load_img(img, target_size=(224,224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def encode_image(img):\n",
    "    img = preprocess_image(img)\n",
    "    feature_vector = model_resnet.predict(img)\n",
    "    feature_vector = feature_vector.reshape(1, feature_vector.shape[1])\n",
    "    return feature_vector\n",
    "\n",
    "with open(\"words_to_index.pkl\", \"rb\") as w2i:\n",
    "    words_to_index = pickle.load(w2i)\n",
    "    \n",
    "with open(\"index_to_words.pkl\", \"rb\") as i2w:\n",
    "    index_to_words = pickle.load(i2w)\n",
    " \n",
    "def predict_caption(photo):\n",
    "\n",
    "    input_text = \"<s>\"\n",
    "    max_length = 35\n",
    "\n",
    "    for i in range(max_length):\n",
    "        sequence = []\n",
    "        for w in input_text.split():\n",
    "            if w in words_to_index:\n",
    "                sequence.append(words_to_index[w])\n",
    "        sequence = pad_sequences([sequence], maxlen = max_length, padding = \"post\")\n",
    "\n",
    "        y_pred = model.predict([photo, sequence])\n",
    "        y_pred = y_pred.argmax()\n",
    "        word = index_to_words[y_pred]\n",
    "        input_text += ' ' + word\n",
    "        \n",
    "        if word == \"<e>\":\n",
    "            break\n",
    "        \n",
    "    final_caption =  input_text.split()\n",
    "    final_caption = final_caption[1:-1]\n",
    "    final_caption = ' '.join(final_caption)\n",
    "    return final_caption\n",
    "\n",
    "def caption_image(image):\n",
    "\n",
    "    encoded_img = encode_image(image)\n",
    "    caption = predict_caption(encoded_img)\n",
    "    return caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_File(path):\n",
    "    with open(path) as f:\n",
    "        line = f.read()\n",
    "    return line\n",
    "\n",
    "path = \"Data/Flickr_Text_Data/Flickr_8k.testImages.txt\"\n",
    "image = Read_File(path)\n",
    "image = image.split(\"\\n\")[:-1]\n",
    "img_name = []\n",
    "for img in image:\n",
    "    image = img.split(\".\")[0]\n",
    "    img_name.append(image)\n",
    "\n",
    "path = \"Data/Flickr_Text_Data/Flickr8k.token.txt\"\n",
    "captions = Read_File(path)\n",
    "captions = captions.split(\"\\n\")[:-1]\n",
    "\n",
    "captions = [i.lower() for i in captions]\n",
    "descriptions = {}\n",
    "\n",
    "for x in captions:\n",
    "    first, second = x.split(\"\\t\")   \n",
    "    second = re.sub(\"[^a-z]+\", \" \", second)\n",
    "    image_name = first.split(\".\")[0]\n",
    "    if image_name in img_name:\n",
    "        if descriptions.get(image_name) is None:\n",
    "            descriptions[image_name] = []       \n",
    "        descriptions[image_name].append(\"<s> \" + second + \" <e>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted = [], []\n",
    "for key, description_list in descriptions.items():\n",
    "    y = caption_image(\"Data/Images/\" + key + \".jpg\")\n",
    "    y = \"<s> \" + y + \" <e>\"\n",
    "    references = [d.split() for d in description_list]\n",
    "    actual.append(references)\n",
    "    predicted.append(y.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU1 SCORE FOR - 1 gram: 0.527321\n",
      "BLEU2 SCORE FOR - 2 gram: 0.273850\n",
      "BLEU3 SCORE FOR - 3 gram: 0.155686\n",
      "BLEU4 SCORE FOR - 4 gram: 0.085186\n"
     ]
    }
   ],
   "source": [
    "print('BLEU1 SCORE FOR - 1 gram: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "print('BLEU2 SCORE FOR - 2 gram: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "print('BLEU3 SCORE FOR - 3 gram: %f' % corpus_bleu(actual, predicted, weights=(0.33, 0.33, 0.33, 0)))\n",
    "print('BLEU4 SCORE FOR - 4 gram: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
